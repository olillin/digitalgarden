---
{"dg-publish":true,"dg-path":"TDA548 - Grundläggande programmering/Lektionsanteckningar/2024-10-01.md","permalink":"/TDA548 - Grundläggande programmering/Lektionsanteckningar/2024-10-01/"}
---

[2024-python-slides-08 - Google Slides](https://docs.google.com/presentation/d/1JzgyAtUB3BzKkM1TXXOZRjPwDAOue4znjMaPQ_PUZ4U/edit#slide=id.ge6b8bec126_0_0)

## Kursinfo

- Nästa vecka börjar objektorienterad programmering

## Linjär regression

**Målet:** Hitta den bästa linjen mellan givna punkter.

### Loss

*Loss* är hur långt alla punkterna är från linjen och beräknas med:
$$
MSE=\frac{1}{\lvert D \rvert }\sum_{(x,y)\in D}(y-prediction(x))^2 
$$
där $D$ är våra punkter, $(x,y)$ är en av dessa punkter och $prediction(x)$ är vår gissning på vad $y$ ska vara för ett visst $x$.

### Algoritmen

> [!Note]
> 
> Eftersom regressionen utförs stegvis kommer den aldrig bli exakt rätt utan bara väldigt nära då den "hoppar fram och tillbaka" över den exakta lösningen.

### Exakta lösningen

$$\theta=(X^{T}X)^{-1}X^{T}y$$


## Sidospår

- Anledningen GPU:er används för maskinlärning är att de kan effektivt och parallellt beräkna matrisoperationer.